{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-TeQ0Rzy89cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b55f189-ca32-41d8-98d5-30426fecc1ac"
      },
      "id": "-TeQ0Rzy89cf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f0d7e3",
      "metadata": {
        "id": "00f0d7e3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from six.moves import cPickle as pickle\n",
        "import os\n",
        "import platform\n",
        "from subprocess import check_output\n",
        "from PIL import Image           # The Python Image Library (PIL)\n",
        "import collections\n",
        "import keras\n",
        "\n",
        "# test harness for evaluating models on the cifar10 dataset\n",
        "import sys\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers, losses\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f85c34",
      "metadata": {
        "id": "f9f85c34"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "numClasses = len(classes)\n",
        "\n",
        "img_rows, img_cols = 32, 32\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':   \n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = load_pickle(f)\n",
        "        X = datadict['data']\n",
        "        #print(len(X[0]))\n",
        "        Y = datadict['labels']\n",
        "        X = X.reshape(10000, 32, 32, 3)\n",
        "        #X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "    \"\"\" load all of cifar \"\"\"\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for b in range(1,6):    \n",
        "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "        X, Y = load_CIFAR_batch(f)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    del X, Y\n",
        "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, Yte      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
        "#def get_CIFAR10_data(num_training=100, num_validation=10, num_test=10):\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = '/content/drive/My Drive/ML/cifar-10-batches-py/'\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    # X_train[num_training: num_training + num_validation]\n",
        "    X_val = X_train[mask]   \n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    x_train = X_train.astype('float32')\n",
        "    x_test = X_test.astype('float32')\n",
        "\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    return x_train, y_train, X_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "zYXORh4VAhzw"
      },
      "id": "zYXORh4VAhzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b59b872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b59b872",
        "outputId": "c082f740-8511-4ba7-b604-6ffe3337faa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (100, 32, 32, 3)\n",
            "Train labels shape:  (100, 10)\n",
            "Validation data shape:  (10, 32, 32, 3)\n",
            "Validation labels shape:  (100, 10, 10)\n",
            "Test data shape:  (10, 32, 32, 3)\n",
            "Test labels shape:  (10, 10)\n"
          ]
        }
      ],
      "source": [
        "# Invoke the above function to get our data.\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR10_data()\n",
        "\n",
        "# One hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, numClasses)\n",
        "y_test = keras.utils.to_categorical(y_test, numClasses)\n",
        "\n",
        "# NOTE: Passing the y_train for y_val\n",
        "y_val = keras.utils.to_categorical(y_train, numClasses)\n",
        "\n",
        "print('Train data shape: ', x_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', x_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', x_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The images are index 0 of the dictionary\n",
        "# They are stored as a 3072 element vector so we need to reshape this into a tensor.\n",
        "# The first dimension is the red/green/blue channel, the second is the pixel row, the third is the pixel column\n",
        "im = x_train[0].reshape(3,32,32)\n",
        "\n",
        "# PIL and matplotlib want the red/green/blue channels last in the matrix. So we just need to rearrange \n",
        "# the tensor to put that dimension last.\n",
        "im = np.transpose(im, axes=[1, 2, 0])  # Put the 0-th dimension at the end\n",
        "\n",
        "# Image are supposed to be unsigned 8-bit integers. If we keep the raw images, then\n",
        "# this line is not needed. However, if we normalize or whiten the image, then the values become\n",
        "# floats. So we need to convert them back to uint8s.\n",
        "im = (im * 255).astype(np.uint8)\n",
        "im = np.uint8(im)  \n",
        "\n",
        "im=Image.fromarray(im)\n",
        "\n",
        "plt.imshow(im);\n",
        "plt.title(\"test\");\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "bLTyf4NRDZ6U",
        "outputId": "82fcfca2-fd2f-411d-89c0-31c076e4fb60"
      },
      "id": "bLTyf4NRDZ6U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15504b28",
      "metadata": {
        "id": "15504b28"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RuOj559Hdy0",
        "outputId": "af5ba894-dd0f-43fc-f16f-328a4fe771c0"
      },
      "id": "5RuOj559Hdy0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "549e378a",
      "metadata": {
        "id": "549e378a"
      },
      "outputs": [],
      "source": [
        "def train_cars_model():\n",
        "    \n",
        "    # Data augmentation\n",
        "    train_datagen = ImageDataGenerator(horizontal_flip=True, height_shift_range=0.1, width_shift_range=0.1)\n",
        "    train_iter = train_datagen.flow(x_train, y_train, batch_size=64)\n",
        "\n",
        "    # Instantiate the callback\n",
        "    # callbacks = myCallback()\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "\n",
        "    # Compile the model\n",
        "    # SGD\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=RMSprop(learning_rate=0.001),\n",
        "                  metrics=['accuracy']) \n",
        "    \n",
        "    # Specify the method to load images from a directory and pass in the appropriate arguments:\n",
        "    # - directory: should be a relative path to the directory containing the data\n",
        "    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n",
        "    # - batch_size: number of images the generator yields when asked for a next batch.\n",
        "    # - class_mode: How the labels are represented. Should be one of \"binary\", \"categorical\" or \"sparse\".\n",
        "    \n",
        "    # fits the model on batches with real-time data augmentation:\n",
        "    history= model.fit(\n",
        "                train_iter,\n",
        "                steps_per_epoch= int(x_train.shape[0] / 64),\n",
        "                epochs=100,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True,\n",
        "                verbose=2, \n",
        "                # callbacks=[callbacks],\n",
        "                initial_epoch= 0\n",
        "            )\n",
        "   \n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9840aaf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "9840aaf2",
        "outputId": "bb115a33-77b3-49c0-efc9-036255b827c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 4s - loss: 4.0597 - accuracy: 0.1094 - val_loss: 6.4661 - val_accuracy: 0.0000e+00 - 4s/epoch - 4s/step\n",
            "[0.109375]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "hist = train_cars_model()\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.plot(hist.history['accuracy'], color='blue', label='train')\n",
        "pyplot.plot(hist.history['val_accuracy'], color='orange', label='val')\n",
        "pyplot.legend(loc='lower right')\n",
        "print (hist.history['accuracy'])\n",
        "\n",
        "# save model\n",
        "hist.model.save(\"/content/drive/My Drive/ML/saved_model.h5\");"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## load tensorflow model\n",
        "new_model = tf.keras.models.load_model(\"/content/drive/My Drive/ML/saved_model.h5\")\n",
        "print(new_model.summary())\n",
        "loss, acc = new_model.evaluate(x_test, y_test, verbose=2)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNtJ42xqYHDP",
        "outputId": "12ade61f-a1b4-42a5-b85d-4dae8c467e3f"
      },
      "id": "MNtJ42xqYHDP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552,362\n",
            "Trainable params: 551,466\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc7ade864c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 1s - loss: 6.4661 - accuracy: 0.0000e+00 - 702ms/epoch - 702ms/step\n",
            "> 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8430a185",
      "metadata": {
        "id": "8430a185",
        "outputId": "9b048b62-f056-4d0b-e5c8-f834a84cf348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 193ms/step\n",
            "[[3.5888009e-04 3.5732093e-03 2.6324212e-03 6.6485238e-04 1.6771468e-04\n",
            "  4.2071808e-04 2.8080183e-09 1.5419755e-03 2.1147267e-04 9.9042881e-01]]\n",
            "/content/drive/My Drive/ML/carcool.png is NOT a car\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/My Drive/ML/carcool.png'\n",
        "img = load_img(path, target_size=(32, 32))\n",
        "x = img_to_array(img)\n",
        "x /= 255\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = hist.model.predict(images, batch_size=10)\n",
        "print(classes)\n",
        "if max(classes[0]) == classes[0][1]:\n",
        "  print(path + \" is a car\")\n",
        "else:\n",
        "  print(path + \" is NOT a car\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}